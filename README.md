# Bandit-algorithm

## Simple Bandit Algorithm Implementation

This repository is an implementation of the simple bandit algorithm, as described in the book by Barto and Sutton. The algorithm serves as a fundamental exploration-exploitation strategy commonly used in reinforcement learning and decision-making scenarios.

### About the Project

The project's core objective is to implement the simple bandit algorithm described in the book by Barto and Sutton. The algorithm is designed to address the exploration-exploitation trade-off by balancing the exploration of uncertain options with the exploitation of known optimal choices. Through this implementation, the project aims to provide a practical demonstration of the algorithm's principles and performance.

### Pseudocode Reference

The pseudocode utilized in this implementation was extracted from the book authored by Barto and Sutton. Please refer to the provided picture for a visual representation of the pseudocode.

![image](https://github.com/NaitikDobariya/Bandit-algorithm/assets/113834773/8f77e90d-6ffe-4bf1-a5cd-af963c39cc50)

### Results

The primary result of this implementation is a graph illustrating the average return after n steps. Multiple curves are presented based on the exploration tendency of the algorithm. These curves depict the algorithm's performance under different levels of exploration, providing insights into its effectiveness in balancing exploration and exploitation.

![bandit_algo_results](https://github.com/NaitikDobariya/Bandit-algorithm/assets/113834773/5671f6f1-ca67-4bee-88bd-d6348582e2ff)

Thank you for your interest 
